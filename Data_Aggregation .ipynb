{
 "cells": [
  {
   "source": [
    "## NLP List ##\n",
    "- Grab data from JSON file\n",
    "- Target XML files and grab articles for individual news sites\n",
    "- Parsing and organizing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Input ##\n",
    "Reading webiste list from JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for JSON Input Section\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two individual files, \n",
    "file_name = \"testdata.json\"     # One website\n",
    "# file_name = \"websites.json\"     # All websites\n",
    "\n",
    "with open(file_name) as file:\n",
    "    websites = []    \n",
    "    # Load in JSON file\n",
    "    data = json.load(file)  \n",
    "    # For each site in JSON file, append to websites\n",
    "    for site in data['target-sites']:\n",
    "        websites.append(site['parse-type']['url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['https://www.cnn.com/sitemaps/cnn/news.xml']\n"
     ]
    }
   ],
   "source": [
    "# You can see the websites by uncommiting the following line\n",
    "print(websites)"
   ]
  },
  {
   "source": [
    "## Creating our corpus ##\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for section\n",
    "import requests\n",
    "import timeit\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Uncomment to test the speed of the aggregation process\n",
    "import time\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "source": [
    "Rather then appending a new entry, we will grow a list. Reference [here](https://stackoverflow.com/a/56746204/7560483)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time:  3.713070900000048\n"
     ]
    }
   ],
   "source": [
    "# Todays current date\n",
    "today = pd.to_datetime(\"today\").tz_localize('US/Central').date()\n",
    "data = [] \n",
    "\n",
    "# Create empty dataframe if articles.csv doesn't exist\n",
    "try:\n",
    "    # Import all articles stored within the csv\n",
    "    df = pd.read_csv('articles.csv', index_col=0)\n",
    "    # Remove all articles not published today\n",
    "    df = df[~(df['pub-date'] == today)]\n",
    "except FileNotFoundError:\n",
    "    # Create empty dataframe if one doesnt exist\n",
    "    df = pd.DataFrame(data, columns=['pub-date','source','name','title','content'])\n",
    "    \n",
    "\n",
    "for site in websites:\n",
    "    # Grab individual sites XML \n",
    "    resp = requests.get(site)\n",
    "\n",
    "    # Parse XML using BeautifulSoup\n",
    "    soup = BeautifulSoup(resp.content, 'lxml-xml')\n",
    "    # For each Article Listed that is today\n",
    "    for article in soup.find_all('url'):\n",
    "        # Grab and parse the publication date of the current article\n",
    "        pub_date = pd.to_datetime(article.publication_date.get_text()).tz_convert('US/Central').date()\n",
    "        # print(pub_date , today , pub_date - today)\n",
    "        if article.loc.get_text() in df['source'].values:     # Continue if previously processed article\n",
    "            continue\n",
    "        elif pub_date < today:     # Continue if pub-date not current date\n",
    "            continue\n",
    "        # Grab and parse the article\n",
    "        page = requests.get(article.loc.get_text())\n",
    "        soup2 = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # Build content based on HTML format\n",
    "        content = []\n",
    "        for ele in soup2.findAll('div',{'class':'zn-body__paragraph'}):\n",
    "            content.append(ele.get_text())\n",
    "        if not content:\n",
    "            for par in soup2.find_all('p'):\n",
    "                content.append(par.get_text())\n",
    "        # Append article onto data list\n",
    "        data.append([\n",
    "            pub_date,\n",
    "            article.loc.get_text(),\n",
    "            article.find('name').get_text(),\n",
    "            article.title.get_text(),\n",
    "            \" \".join(content)\n",
    "        ])\n",
    "        \n",
    "        # Sleep for etiquette\n",
    "        time.sleep(.5)\n",
    "\n",
    "# Concat the data as a DataFrame object with respects to existing DataFrame\n",
    "df = pd.concat([df, pd.DataFrame(data, columns=['pub-date','source','name','title','content'])], ignore_index=True)\n",
    "\n",
    "# Final revision on data aggregated \n",
    "df['pub-date'] = pd.to_datetime(df['pub-date'], utc=True)\n",
    "df['content'] = df['content'].astype(str)\n",
    "# Export data\n",
    "df.to_csv(\"articles.csv\")\n",
    "\n",
    "# Uncomment to test the speed of the aggregation process\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time: \", stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   pub-date  \\\n",
       "0 2021-02-01 00:00:00+00:00   \n",
       "1 2021-02-01 00:00:00+00:00   \n",
       "2 2021-02-01 00:00:00+00:00   \n",
       "3 2021-02-01 00:00:00+00:00   \n",
       "4 2021-02-01 00:00:00+00:00   \n",
       "\n",
       "                                              source               name  \\\n",
       "0  https://www.cnn.com/2021/02/01/us/aclu-first-b...                CNN   \n",
       "1  https://www.cnn.com/2021/02/01/politics/joe-ma...                CNN   \n",
       "2  https://www.cnn.com/2021/02/01/health/us-coron...                CNN   \n",
       "3  https://www.cnn.com/2021/02/01/investing/googl...                CNN   \n",
       "4  https://edition.cnn.com/2021/02/01/europe/nean...  CNN International   \n",
       "\n",
       "                                               title  \\\n",
       "0  ACLU, for first time in its 101-year history, ...   \n",
       "1  White House reached out to Manchin after Harri...   \n",
       "2  The US is in an &apos;absolute race&apos; with...   \n",
       "3  Google investors may have forgotten how much l...   \n",
       "4  Prehistoric teeth hint at Stone Age sex with N...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The ACLU made the announcement Monday, calling...   \n",
       "1  The outreach comes after Harris' apparent move...   \n",
       "2  \"What concerns me most is that we already know...   \n",
       "3  Alphabet (GOOGL) is trading near an all-time h...   \n",
       "4  During this time, Homo sapiens and Neanderthal...   \n",
       "\n",
       "                                             summary  \n",
       "0  \"After beginning my career as an ACLU fellow, ...  \n",
       "1  In an interview with WSAZ Thursday, Harris sai...  \n",
       "2  While the state has the capacity to give 250,0...  \n",
       "3  But broader concerns about the pandemic could ...  \n",
       "4  The team was trying to recover DNA from the te...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pub-date</th>\n      <th>source</th>\n      <th>name</th>\n      <th>title</th>\n      <th>content</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-02-01 00:00:00+00:00</td>\n      <td>https://www.cnn.com/2021/02/01/us/aclu-first-b...</td>\n      <td>CNN</td>\n      <td>ACLU, for first time in its 101-year history, ...</td>\n      <td>The ACLU made the announcement Monday, calling...</td>\n      <td>\"After beginning my career as an ACLU fellow, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-02-01 00:00:00+00:00</td>\n      <td>https://www.cnn.com/2021/02/01/politics/joe-ma...</td>\n      <td>CNN</td>\n      <td>White House reached out to Manchin after Harri...</td>\n      <td>The outreach comes after Harris' apparent move...</td>\n      <td>In an interview with WSAZ Thursday, Harris sai...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-02-01 00:00:00+00:00</td>\n      <td>https://www.cnn.com/2021/02/01/health/us-coron...</td>\n      <td>CNN</td>\n      <td>The US is in an &amp;apos;absolute race&amp;apos; with...</td>\n      <td>\"What concerns me most is that we already know...</td>\n      <td>While the state has the capacity to give 250,0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-02-01 00:00:00+00:00</td>\n      <td>https://www.cnn.com/2021/02/01/investing/googl...</td>\n      <td>CNN</td>\n      <td>Google investors may have forgotten how much l...</td>\n      <td>Alphabet (GOOGL) is trading near an all-time h...</td>\n      <td>But broader concerns about the pandemic could ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-02-01 00:00:00+00:00</td>\n      <td>https://edition.cnn.com/2021/02/01/europe/nean...</td>\n      <td>CNN International</td>\n      <td>Prehistoric teeth hint at Stone Age sex with N...</td>\n      <td>During this time, Homo sapiens and Neanderthal...</td>\n      <td>The team was trying to recover DNA from the te...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Cleaning and preparations ## "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Cleaning and preparations\n",
    "import numpy as np\n",
    "import heapq\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "source": [
    "Now that we've aggreggated articles for our data,lets preview an article."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'The ACLU made the announcement Monday, calling Archer \"an established civil rights attorney, scholar, and teacher.\" In addition to her professorship, Archer is the co-faculty director at NYU\\'s Center on Race, Inequality, and the Law, and the director of the Civil Rights Clinic at NYU School of Law. Archer has been a part of the ACLU for years, beginning her career as a legal fellow in the ACLU Racial Justice Program, the organization stated. She\\'s been a member of the board since 2009 and a general counsel since 2017. \"After beginning my career as an ACLU fellow, it is an honor to come full circle and now lead the organization as board president,\" Archer said in a statement. \"The ACLU has proven itself as an invaluable voice in the fight for civil rights in the last four years of the Trump era, and we are better positioned than ever to face the work ahead.\" Susan Herman previously held the role, serving for 12 years.  Archer\\'s duties will include leading its more than 60 members in creating organizational policy, as well as overseeing things like the nonprofit\\'s finances. '"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df['content'][0]"
   ]
  },
  {
   "source": [
    "Notice the symbols and characters within the article content. Before we calculate the frequencies, lets use regex to clean things up by defining some functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = np.full([len(df)], \"\", dtype=np.object)\n",
    "for index, row in df.iterrows():\n",
    "    # Remove all extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', row['content'])\n",
    "    # Remove all numbers and special characters, used for frequency\n",
    "    format_text = re.sub('[^a-zA-Z]', ' ', text )\n",
    "    format_text = re.sub(r'\\s+', ' ', format_text)\n",
    "\n",
    "    # Remove stopwords from tokenized array\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    word_tokens = np.array(word_tokenize(format_text))\n",
    "    format_text = np.array([word for word in word_tokens if not word in stop_words])\n",
    "\n",
    "    # Splitting sentences\n",
    "    sentence_list = np.array(text.split('. '))\n",
    "    \n",
    "    word_freq = {}\n",
    "    for word in format_text:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else: \n",
    "            word_freq[word] += 1\n",
    "\n",
    "    max_req = max(word_freq.values(), default=0)\n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word] = (word_freq[word]/max_req)\n",
    "    \n",
    "    sentence_score = {}\n",
    "    sentence_avg = round(1.5*sum([len(sent.split(' ')) for sent in sentence_list])/len(sentence_list))\n",
    "    for sentence in sentence_list:\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in word_freq.keys():\n",
    "                if len(sentence.split(' ')) < sentence_avg:\n",
    "                    if sentence not in sentence_score.keys():\n",
    "                        sentence_score[sentence] = word_freq[word]\n",
    "                    else:\n",
    "                        sentence_score[sentence] += word_freq[word]\n",
    "\n",
    "    summary_sentences = heapq.nlargest(7, sentence_score, key=sentence_score.get)\n",
    "    summary_data[index] = '. '.join(summary_sentences)+\".\"\n",
    "\n",
    "# Append new column\n",
    "df['summary'] = summary_data \n",
    "df.to_csv(\"articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"Rubio's comments about the bus incident The video's description of Rubio's comments about the bus incident is fair enough\", 'On January 8, Rubio posted a video statement on Twitter that mixed criticism of the insurrection with criticism of others', 'This claim, about Rubio contributing to harmful political \"conditions,\" is a more nuanced and defensible claim than the suggestion in the video that insurrectionists heard and acted on Rubio\\'s words', 'The video goes on to say that Rubio applauded the convoy of Donald Trump supporters that was filmed surrounding a Joe Biden campaign bus on an interstate highway in Texas in October', \"The video itself, however, doesn't offer this kind of nuanced criticism of the strength of Rubio's responses to the attack\", 'Still, though, he indisputably condemned the insurrection the MeidasTouch video claims he did not condemn.', 'This is 3rd world style anti-American anarchy.\" That night on Fox News, Rubio said to host Tucker Carlson that the insurrection was \"completely, a hundred percent inexcusable\" no matter what the participants\\' motivations']\n"
     ]
    }
   ],
   "source": [
    "print(summary_sentences)\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Content:\nThe ACLU made the announcement Monday, calling Archer \"an established civil rights attorney, scholar, and teacher.\" In addition to her professorship, Archer is the co-faculty director at NYU's Center on Race, Inequality, and the Law, and the director of the Civil Rights Clinic at NYU School of Law. Archer has been a part of the ACLU for years, beginning her career as a legal fellow in the ACLU Racial Justice Program, the organization stated. She's been a member of the board since 2009 and a general counsel since 2017. \"After beginning my career as an ACLU fellow, it is an honor to come full circle and now lead the organization as board president,\" Archer said in a statement. \"The ACLU has proven itself as an invaluable voice in the fight for civil rights in the last four years of the Trump era, and we are better positioned than ever to face the work ahead.\" Susan Herman previously held the role, serving for 12 years.  Archer's duties will include leading its more than 60 members in creating organizational policy, as well as overseeing things like the nonprofit's finances. \nSummary:\n\"After beginning my career as an ACLU fellow, it is an honor to come full circle and now lead the organization as board president,\" Archer said in a statement. Archer has been a part of the ACLU for years, beginning her career as a legal fellow in the ACLU Racial Justice Program, the organization stated. Archer's duties will include leading its more than 60 members in creating organizational policy, as well as overseeing things like the nonprofit's finances. She's been a member of the board since 2009 and a general counsel since 2017.\n"
     ]
    }
   ],
   "source": [
    "# Now lets compare the differences between the content and summary for a random element\n",
    "print('Content:\\n'+df['content'][0])\n",
    "print('Summary:\\n'+df['summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}